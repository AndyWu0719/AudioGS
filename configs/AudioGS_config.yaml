# AudioGS Configuration: Pure Autoencoder (STFT Reconstruction)
# =========================================================

# Data
data:
  dataset_path: "/data0/determined/users/andywu/GS-TS/data/raw/LibriTTS_R"
  sample_rate: 24000
  subsets: ["train-clean-100", "train-clean-360"]
  val_subsets: ["dev-clean"]
  max_audio_length: 3.0      # 3 seconds for memory efficiency

# Encoder Model
encoder_model:
  input_mel_bins: 80
  hidden_channels: 256
  grid_freq_bins: 128
  atoms_per_cell: 2
  time_downsample_factor: 240  # 24000Hz / 240 = 100Hz frame rate
  num_layers: 6
  use_conformer: true
  use_checkpointing: true  # Gradient checkpointing for memory savings

# Training (Pure Autoencoder - No GAN)
training:
  batch_size: 32              # Single batch size (no phase switching)
  accumulation_steps: 8      # Effective batch = 8*8*4GPUs = 256
  learning_rate: 0.0002      # AdamW
  max_steps: 100000
  warmup_steps: 1000
  val_interval: 2000
  save_interval: 10000
  log_interval: 10

# Loss (Multi-Scale STFT Reconstruction)
loss:
  fft_sizes: [2048, 1024, 512, 128]
  hop_sizes: [512, 256, 128, 32]
  win_lengths: [2048, 1024, 512, 128]
  spectral_weight: 1.0       # Multi-scale STFT
  mel_weight: 45.0           # Strong mel reconstruction
  time_domain_weight: 0.1    # Light time-domain L1
  phase_weight: 2.0          # Phase-aware loss
  amp_l1_weight: 0.0001      # Very light amplitude L1 (natural sparsity)
  amp_reg_weight: 0.0        # Disabled (use amp_l1_weight instead)
  pre_emp_weight: 2.0        # Pre-emphasis for high-frequency detail

# Distributed Training
distributed:
  backend: "nccl"
  find_unused_parameters: false